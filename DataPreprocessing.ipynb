{"cells":[{"cell_type":"markdown","id":"d54b57eb","metadata":{"id":"d54b57eb"},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"id":"4505f69b","metadata":{"id":"4505f69b"},"outputs":[],"source":["import nltk\n","import numpy as np\n","import pandas as pd\n","\n","import re                                  # library for regular expression operations\n","import string                              # for string operations\n","\n","from deep_translator import GoogleTranslator\n","import stopwordsiso as stopwords           # module for stop words\n","from nltk.stem import PorterStemmer, WordNetLemmatizer        # module for stemming\n","from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"]},{"cell_type":"markdown","id":"30b21a72","metadata":{"id":"30b21a72"},"source":["## Read Dataset"]},{"cell_type":"markdown","id":"abd83549","metadata":{"id":"abd83549"},"source":["**Raw Twitter Data March 2020 - December 2020**"]},{"cell_type":"code","execution_count":null,"id":"98334d4e","metadata":{"scrolled":false,"id":"98334d4e","outputId":"02d920c3-1596-4453-d412-0af0fb2beea8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Date</th>\n","      <th>User</th>\n","      <th>Tweet</th>\n","      <th>Likes</th>\n","      <th>Retweets</th>\n","      <th>Hashtags</th>\n","      <th>Language</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2020-12-30 13:53:43+00:00</td>\n","      <td>clydebaltz</td>\n","      <td>\"ganda talaga pag online class kase makakatipi...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2020-12-30 12:03:29+00:00</td>\n","      <td>Shuwbeeeeee</td>\n","      <td>Online class* Dami pang pending activities htt...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2020-12-30 08:29:38+00:00</td>\n","      <td>daksprincess</td>\n","      <td>Mag 2021 na back to school nasad ay bck to onl...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2020-12-30 07:18:21+00:00</td>\n","      <td>caamsahamnida</td>\n","      <td>Wala dyud ko kaila aning mga ga \"hi maam\" sako...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2020-12-30 06:15:09+00:00</td>\n","      <td>CydLouie_</td>\n","      <td>Sobrang fucked up ng online class. Naiinis na ...</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                       Date           User  \\\n","0           0  2020-12-30 13:53:43+00:00     clydebaltz   \n","1           1  2020-12-30 12:03:29+00:00    Shuwbeeeeee   \n","2           2  2020-12-30 08:29:38+00:00   daksprincess   \n","3           3  2020-12-30 07:18:21+00:00  caamsahamnida   \n","4           4  2020-12-30 06:15:09+00:00      CydLouie_   \n","\n","                                               Tweet  Likes  Retweets  \\\n","0  \"ganda talaga pag online class kase makakatipi...      1         0   \n","1  Online class* Dami pang pending activities htt...      0         0   \n","2  Mag 2021 na back to school nasad ay bck to onl...      0         0   \n","3  Wala dyud ko kaila aning mga ga \"hi maam\" sako...      0         0   \n","4  Sobrang fucked up ng online class. Naiinis na ...      6         0   \n","\n","  Hashtags Language  \n","0      NaN       tl  \n","1      NaN       en  \n","2      NaN       tl  \n","3      NaN       tl  \n","4      NaN       tl  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data_1 = pd.read_csv(r'project\\2020Mar-2020Dec_raw-tweets.csv');\n","data_1.head()"]},{"cell_type":"markdown","id":"6aa89e26","metadata":{"id":"6aa89e26"},"source":["**Raw Twitter Data January 2021 - December 2021**"]},{"cell_type":"code","execution_count":null,"id":"e172bcd9","metadata":{"id":"e172bcd9","outputId":"8c9e9130-4ba0-4c27-dbb1-893558432189"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Date</th>\n","      <th>User</th>\n","      <th>Tweet</th>\n","      <th>Likes</th>\n","      <th>Hashtags</th>\n","      <th>Language</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2021-12-30 21:01:53+00:00</td>\n","      <td>emeeny</td>\n","      <td>is still gradually increasing. Ayoko na po mat...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2021-12-30 17:47:20+00:00</td>\n","      <td>la_graciaa</td>\n","      <td>@aimie1109 ako din kaso back to online class n...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2021-12-29 15:50:25+00:00</td>\n","      <td>saimallow</td>\n","      <td>For some reasons, this year has been, for me, ...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2021-12-29 11:08:55+00:00</td>\n","      <td>a7dcmanv37</td>\n","      <td>Online class pa tangina walang top performing ...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2021-12-28 16:19:53+00:00</td>\n","      <td>ArvinOcampo13</td>\n","      <td>#NahanapNaSiArvin NAHANAP KONA SARILI KO, NEED...</td>\n","      <td>2</td>\n","      <td>['NahanapNaSiArvin']</td>\n","      <td>tl</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                       Date           User  \\\n","0           0  2021-12-30 21:01:53+00:00         emeeny   \n","1           1  2021-12-30 17:47:20+00:00     la_graciaa   \n","2           2  2021-12-29 15:50:25+00:00      saimallow   \n","3           3  2021-12-29 11:08:55+00:00     a7dcmanv37   \n","4           4  2021-12-28 16:19:53+00:00  ArvinOcampo13   \n","\n","                                               Tweet  Likes  \\\n","0  is still gradually increasing. Ayoko na po mat...      0   \n","1  @aimie1109 ako din kaso back to online class n...      1   \n","2  For some reasons, this year has been, for me, ...      0   \n","3  Online class pa tangina walang top performing ...      0   \n","4  #NahanapNaSiArvin NAHANAP KONA SARILI KO, NEED...      2   \n","\n","               Hashtags Language  \n","0                   NaN       tl  \n","1                   NaN       tl  \n","2                   NaN       en  \n","3                   NaN       tl  \n","4  ['NahanapNaSiArvin']       tl  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data_2 = pd.read_csv(r'project\\2021Jan-2021Dec_raw-tweets.csv');\n","data_2.head()"]},{"cell_type":"markdown","id":"4cf2f672","metadata":{"id":"4cf2f672"},"source":["**Raw Twitter Data January 2022 - December 2022**"]},{"cell_type":"code","execution_count":null,"id":"d1120257","metadata":{"id":"d1120257","outputId":"9dccf6f4-b444-4bec-eae2-c977fd294083"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Date</th>\n","      <th>User</th>\n","      <th>Tweet</th>\n","      <th>Likes</th>\n","      <th>Retweets</th>\n","      <th>Hashtags</th>\n","      <th>Language</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2022-12-07 22:00:00+00:00</td>\n","      <td>ActsReviewCtr</td>\n","      <td>Congratulations to BEATRICE ISABELLE UY from 2...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2022-12-07 14:44:32+00:00</td>\n","      <td>ActsReviewCtr</td>\n","      <td>Congratulations to MARIA LOREINA CRUZ from 202...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2022-12-07 10:01:56+00:00</td>\n","      <td>AFManille</td>\n","      <td>ðŸ“¢ [TRIAL CLASS IN DECEMBER]\\nEager to embark o...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>['AFMTrials']</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2022-12-07 09:31:03+00:00</td>\n","      <td>ara_d_here</td>\n","      <td>@_artbacccjip ay huhu ga-hotspot man gud ko ka...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2022-12-07 08:27:34+00:00</td>\n","      <td>LeenLuckyWins</td>\n","      <td>Antok na antok akooo, idlip muna tas may onlin...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>tl</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                       Date           User  \\\n","0           0  2022-12-07 22:00:00+00:00  ActsReviewCtr   \n","1           1  2022-12-07 14:44:32+00:00  ActsReviewCtr   \n","2           2  2022-12-07 10:01:56+00:00      AFManille   \n","3           3  2022-12-07 09:31:03+00:00     ara_d_here   \n","4           4  2022-12-07 08:27:34+00:00  LeenLuckyWins   \n","\n","                                               Tweet  Likes  Retweets  \\\n","0  Congratulations to BEATRICE ISABELLE UY from 2...      1         0   \n","1  Congratulations to MARIA LOREINA CRUZ from 202...      1         0   \n","2  ðŸ“¢ [TRIAL CLASS IN DECEMBER]\\nEager to embark o...      1         0   \n","3  @_artbacccjip ay huhu ga-hotspot man gud ko ka...      0         0   \n","4  Antok na antok akooo, idlip muna tas may onlin...      0         0   \n","\n","        Hashtags Language  \n","0            NaN       en  \n","1            NaN       en  \n","2  ['AFMTrials']       en  \n","3            NaN       tl  \n","4            NaN       tl  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data_3 = pd.read_csv(r'project\\2022Jan-2022Dec_raw-tweets.csv');\n","data_3.head()"]},{"cell_type":"markdown","id":"0cf56b8e","metadata":{"id":"0cf56b8e"},"source":["## PRE PROCESSING"]},{"cell_type":"markdown","id":"24d0a0bc","metadata":{"id":"24d0a0bc"},"source":["### Remove Punctuations, digits, hyperlinks, Twitter marks and styles\n","Some tweets are composed of text with hashtags, retweet marks, and hyperlinks. Regular expressions will be used to remove them from a tweet."]},{"cell_type":"code","execution_count":null,"id":"d6cab5ab","metadata":{"id":"d6cab5ab"},"outputs":[],"source":["def remove_hyperlinks_marks_styles(tweet):\n","    \n","    # remove old style retweet text \"RT\"\n","    new_tweet = re.sub(r'^RT[\\s]+', '', tweet)\n","\n","    # remove hyperlinks and mentions\n","    new_tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", new_tweet)\n","    \n","    # remove hashtags-only removing the hash # sign from the word\n","    new_tweet = re.sub(r'#', '', new_tweet)\n","    \n","    # remove digits\n","    new_tweet = re.sub(r'[\\d-]', '', new_tweet)\n","    \n","    # remove punctuations\n","    new_tweet = re.sub(r'[^\\w\\s]', '', new_tweet)\n","    \n","    # remove extra space\n","    new_tweet = re.sub(' +', ' ', new_tweet)\n","    \n","    return new_tweet\n"]},{"cell_type":"markdown","id":"f1b67b03","metadata":{"id":"f1b67b03"},"source":["### Tokenize the string\n","Split a string into individual words."]},{"cell_type":"code","execution_count":null,"id":"73235868","metadata":{"id":"73235868"},"outputs":[],"source":["# instantiate tokenizer class\n","tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n","\n","def tokenize_tweet(tweet):\n","    # translate Filipino words to english language\n","    # word_lang = (translator.detect(txt_3)).lang \n","    # tweet_trans = translator.translate(tweet, src=word_lang, dest='en').text\n","    tweet_trans = GoogleTranslator(source='auto', target='en').translate(tweet)\n","    \n","    tweet_tokens = tokenizer.tokenize(tweet_trans)\n","    return tweet_tokens"]},{"cell_type":"markdown","id":"d5f0b492","metadata":{"id":"d5f0b492"},"source":["### Remove stop words and punctuations\n","Remove stop words and punctuations. Stop words are words that don't add significant meaning to the text. For example, 'i' and 'me'."]},{"cell_type":"code","execution_count":null,"id":"0d17e743","metadata":{"id":"0d17e743"},"outputs":[],"source":["#Import the english and tagalog stop words list from NLTK\n","stop_words = stopwords.stopwords([\"en\", \"tl\"])\n","punctuations = string.punctuation\n","\n","def remove_stopwords_punctuations(tweet_tokens):\n","    tweets_clean = []\n","    \n","    for word in tweet_tokens:\n","        if (word not in stop_words and word not in punctuations):\n","            tweets_clean.append(word)\n","            \n","    return tweets_clean"]},{"cell_type":"markdown","id":"7c37dea2","metadata":{"id":"7c37dea2"},"source":["### Lemmatize"]},{"cell_type":"code","execution_count":null,"id":"48a7a7d2","metadata":{"id":"48a7a7d2"},"outputs":[],"source":["lemmatizer = WordNetLemmatizer()   \n","#an instance of Word Net Lemmatizer\n","\n","\n","def lemmatize_text(tweets_clean):\n","    \n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in tweets_clean] \n","    \n","    return lemmatized_words"]},{"cell_type":"markdown","id":"9a6c8c44","metadata":{"id":"9a6c8c44"},"source":["### Stemming"]},{"cell_type":"code","execution_count":null,"id":"7c627a86","metadata":{"id":"7c627a86"},"outputs":[],"source":["stemmer = PorterStemmer()\n","\n","def get_stem(tweets_clean):\n","    \n","    tweets_stem = []\n","    \n","    for word in tweets_clean:\n","        stem_word = stemmer.stem(word)\n","        tweets_stem.append(stem_word)\n","        \n","    return tweets_stem\n"]},{"cell_type":"markdown","id":"7bd4b03b","metadata":{"id":"7bd4b03b"},"source":["### Remove Less 2 Character Strings"]},{"cell_type":"code","execution_count":null,"id":"1517d6c5","metadata":{"id":"1517d6c5"},"outputs":[],"source":["def remove_to2_Char(tweets_clean):\n","    \n","    tweets = []\n","    \n","    for word in tweets_clean:\n","        if len(word) > 2:\n","            tweets.append(word)\n","        \n","    return tweets"]},{"cell_type":"code","execution_count":null,"id":"b24dc582","metadata":{"scrolled":false,"id":"b24dc582","outputId":"8f29db97-739d-48ac-e90c-e81cee4d0c28"},"outputs":[{"name":"stdout","output_type":"stream","text":["Online class really got me complaining bout stuffs then still Iâ€™d comply ðŸ˜‘ðŸ˜¬\n","\n","Removed hyperlinks, Twitter marks and styles:\n","Online class really got me complaining bout stuffs then still Id comply \n","\n","Tokenize the string:\n","['online', 'class', 'really', 'got', 'me', 'complaining', 'bout', 'stuffs', 'then', 'still', 'id', 'comply']\n","\n","Remove stop words\n","['online', 'class', 'complaining', 'bout', 'stuffs', 'comply']\n","\n","Get lemma of each word:\n","['online', 'class', 'complaining', 'bout', 'stuff', 'comply']\n","\n","Get stem of each word:\n","['onlin', 'class', 'complain', 'bout', 'stuff', 'compli']\n","\n","Remove 1 and 2 character words:\n","['onlin', 'class', 'complain', 'bout', 'stuff', 'compli']\n"]}],"source":["tweet_example = data_1['Tweet'].iloc[722]\n","print(tweet_example)\n","\n","processed_tweet = remove_hyperlinks_marks_styles(tweet_example)\n","print(\"\\nRemoved hyperlinks, Twitter marks and styles:\")\n","print(processed_tweet)\n","\n","tweet_tokens = tokenize_tweet(processed_tweet)\n","print(\"\\nTokenize the string:\")\n","print(tweet_tokens)\n","\n","tweets_clean = remove_stopwords_punctuations(tweet_tokens)\n","print(\"\\nRemove stop words\")\n","print(tweets_clean)\n","\n","tweets_lemma = lemmatize_text(tweets_clean)\n","print(\"\\nGet lemma of each word:\")\n","print(tweets_lemma)\n","\n","tweets_stem = get_stem(tweets_lemma)\n","print(\"\\nGet stem of each word:\")\n","print(tweets_stem)\n","\n","tweets_char_remove = remove_to2_Char(tweets_stem)\n","print(\"\\nRemove 1 and 2 character words:\")\n","print(tweets_char_remove)"]},{"cell_type":"markdown","id":"7d0874fd","metadata":{"id":"7d0874fd"},"source":["### Pre Process Main Function"]},{"cell_type":"code","execution_count":null,"id":"dc7c91c9","metadata":{"id":"dc7c91c9"},"outputs":[],"source":["def process_tweet(tweet):\n","    processed_tweet = remove_hyperlinks_marks_styles(tweet)\n","    tweet_tokens = tokenize_tweet(processed_tweet)\n","    tweets_clean = remove_stopwords_punctuations(tweet_tokens)\n","    tweets_lemma = lemmatize_text(tweets_clean)\n","    tweets_stem = get_stem(tweets_lemma)\n","    tweets_char_remove = remove_to2_Char(tweets_stem)\n","    \n","    return ' '.join(tweets_char_remove)"]},{"cell_type":"code","execution_count":null,"id":"47ff9cb0","metadata":{"id":"47ff9cb0"},"outputs":[],"source":["def remove_dup_empty_rows(tweet_data):\n","    tweet_data = tweet_data.drop_duplicates('Processed Tweets')\n","    \n","    # delete row with empty cell\n","    tweet_data['Processed Tweets'].replace('', np.nan, inplace=True)\n","    \n","    tweet_data = tweet_data.dropna(subset=['Processed Tweets'])\n","    tweet_data = tweet_data.reset_index(drop=True)\n","    \n","    return tweet_data"]},{"cell_type":"markdown","id":"b853acd7","metadata":{"id":"b853acd7"},"source":["### Year 1 Processed Data"]},{"cell_type":"code","execution_count":null,"id":"8e8d0e1f","metadata":{"id":"8e8d0e1f"},"outputs":[],"source":["processed_data_1 = pd.DataFrame()\n","processed_data_1['index'] = data_1.index"]},{"cell_type":"code","execution_count":null,"id":"91cf35b4","metadata":{"scrolled":false,"id":"91cf35b4"},"outputs":[],"source":["processed_data_1['Processed Tweets'] = data_1['Tweet'].apply(process_tweet)"]},{"cell_type":"code","execution_count":null,"id":"1e26ec47","metadata":{"id":"1e26ec47","outputId":"4ece81a1-afc5-4d0b-8a1f-9905e1d4d8c6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Processed Tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>nice onlin class save money ver trsr nct boyz ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>onlin class pend activ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>school nasad onlin class hahahaha</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>guy hard familiar onlin class haha</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>onlin class fuck sick</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13127</th>\n","      <td>13127</td>\n","      <td>onlin class studi lesson</td>\n","    </tr>\n","    <tr>\n","      <th>13128</th>\n","      <td>13128</td>\n","      <td>blackboard onlin class brownout cut class</td>\n","    </tr>\n","    <tr>\n","      <th>13129</th>\n","      <td>13129</td>\n","      <td>peopl angri onlin class week week term</td>\n","    </tr>\n","    <tr>\n","      <th>13130</th>\n","      <td>13130</td>\n","      <td>karmi iarmi class trend hate onlin attack cons...</td>\n","    </tr>\n","    <tr>\n","      <th>13131</th>\n","      <td>13131</td>\n","      <td>jusm onlin class call hahahahaha wowerz</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13132 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["       index                                   Processed Tweets\n","0          0  nice onlin class save money ver trsr nct boyz ...\n","1          1                             onlin class pend activ\n","2          2                  school nasad onlin class hahahaha\n","3          3                 guy hard familiar onlin class haha\n","4          4                              onlin class fuck sick\n","...      ...                                                ...\n","13127  13127                           onlin class studi lesson\n","13128  13128          blackboard onlin class brownout cut class\n","13129  13129             peopl angri onlin class week week term\n","13130  13130  karmi iarmi class trend hate onlin attack cons...\n","13131  13131            jusm onlin class call hahahahaha wowerz\n","\n","[13132 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(processed_data_1)"]},{"cell_type":"markdown","id":"434b2e2f","metadata":{"id":"434b2e2f"},"source":["### Year 2 Processed Data"]},{"cell_type":"code","execution_count":null,"id":"502db30f","metadata":{"id":"502db30f"},"outputs":[],"source":["processed_data_2 = pd.DataFrame()\n","processed_data_2['index'] = data_2.index"]},{"cell_type":"code","execution_count":null,"id":"76fff2e1","metadata":{"id":"76fff2e1"},"outputs":[],"source":["processed_data_2['Processed Tweets'] = data_2['Tweet'].apply(process_tweet)"]},{"cell_type":"code","execution_count":null,"id":"bd5e57ea","metadata":{"id":"bd5e57ea","outputId":"f7658227-037d-415b-d88a-1d32821b060c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Processed Tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>gradual increas close border late decemb covid...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>onlin class shet yawqna hahahahahahahaha lol</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>reason fastest ata wala masyadong ganap life o...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>onlin class perform school amp</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>nanapansiarvin onlin class hhahhaahahh</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1791</th>\n","      <td>1791</td>\n","      <td>love onlin class school hahahahahahah</td>\n","    </tr>\n","    <tr>\n","      <th>1792</th>\n","      <td>1792</td>\n","      <td>quarter sem memor sched onlin class</td>\n","    </tr>\n","    <tr>\n","      <th>1793</th>\n","      <td>1793</td>\n","      <td>badiday recess onlin class start</td>\n","    </tr>\n","    <tr>\n","      <th>1794</th>\n","      <td>1794</td>\n","      <td>drink coffe onlin class fall asleep class</td>\n","    </tr>\n","    <tr>\n","      <th>1795</th>\n","      <td>1795</td>\n","      <td>ghad morn internet connect brother onlin class...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1796 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["      index                                   Processed Tweets\n","0         0  gradual increas close border late decemb covid...\n","1         1       onlin class shet yawqna hahahahahahahaha lol\n","2         2  reason fastest ata wala masyadong ganap life o...\n","3         3                     onlin class perform school amp\n","4         4             nanapansiarvin onlin class hhahhaahahh\n","...     ...                                                ...\n","1791   1791              love onlin class school hahahahahahah\n","1792   1792                quarter sem memor sched onlin class\n","1793   1793                   badiday recess onlin class start\n","1794   1794          drink coffe onlin class fall asleep class\n","1795   1795  ghad morn internet connect brother onlin class...\n","\n","[1796 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(processed_data_2)"]},{"cell_type":"markdown","id":"ebddefbe","metadata":{"id":"ebddefbe"},"source":["### Year 3 Processed Data"]},{"cell_type":"code","execution_count":null,"id":"8613e30f","metadata":{"id":"8613e30f"},"outputs":[],"source":["processed_data_3 = pd.DataFrame()\n","processed_data_3['index'] = data_3.index"]},{"cell_type":"code","execution_count":null,"id":"bc29e4fb","metadata":{"id":"bc29e4fb"},"outputs":[],"source":["processed_data_3['Processed Tweets'] = data_3['Tweet'].apply(process_tweet)"]},{"cell_type":"code","execution_count":null,"id":"b878372c","metadata":{"id":"b878372c","outputId":"85648411-a085-4a8c-924c-f546f7f8a1b1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Processed Tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>congratul beatric isabel onlin class batch pas...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>congratul maria loreina cruz onlin class batch...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>trial class decemb eager embark french adventu...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>hey hotspot laptop onlin class money onlin ftf...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>sleepi nap onlin class tomorrow</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2314</th>\n","      <td>2314</td>\n","      <td>onlin class lazi studi hard</td>\n","    </tr>\n","    <tr>\n","      <th>2315</th>\n","      <td>2315</td>\n","      <td>onlin class guy</td>\n","    </tr>\n","    <tr>\n","      <th>2316</th>\n","      <td>2316</td>\n","      <td>forgot onlin class</td>\n","    </tr>\n","    <tr>\n","      <th>2317</th>\n","      <td>2317</td>\n","      <td>smell onlin class season hope</td>\n","    </tr>\n","    <tr>\n","      <th>2318</th>\n","      <td>2318</td>\n","      <td>hey onlin class readi</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2319 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["      index                                   Processed Tweets\n","0         0  congratul beatric isabel onlin class batch pas...\n","1         1  congratul maria loreina cruz onlin class batch...\n","2         2  trial class decemb eager embark french adventu...\n","3         3  hey hotspot laptop onlin class money onlin ftf...\n","4         4                    sleepi nap onlin class tomorrow\n","...     ...                                                ...\n","2314   2314                        onlin class lazi studi hard\n","2315   2315                                    onlin class guy\n","2316   2316                                 forgot onlin class\n","2317   2317                      smell onlin class season hope\n","2318   2318                              hey onlin class readi\n","\n","[2319 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(processed_data_3)"]},{"cell_type":"markdown","id":"55de5660","metadata":{"id":"55de5660"},"source":["### Save to csv file"]},{"cell_type":"code","execution_count":null,"id":"141c25ac","metadata":{"id":"141c25ac"},"outputs":[],"source":["processed_data_1.to_csv('2020Mar-2020Dec_processed-tweets.csv')\n","processed_data_2.to_csv('2021Mar-2021Dec_processed-tweets.csv')\n","processed_data_3.to_csv('2022Jan-2022Dec_processed-tweets.csv')"]},{"cell_type":"markdown","id":"96b7d91b","metadata":{"id":"96b7d91b"},"source":["### Combine all processed dataset 2020 - 2022"]},{"cell_type":"code","execution_count":null,"id":"d1b4737d","metadata":{"id":"d1b4737d"},"outputs":[],"source":["combined_processed_data = pd.DataFrame()"]},{"cell_type":"code","execution_count":null,"id":"704b57a4","metadata":{"id":"704b57a4"},"outputs":[],"source":["combined_processed_data = combined_processed_data.append(processed_data_1, ignore_index = True)"]},{"cell_type":"code","execution_count":null,"id":"25dc9fc7","metadata":{"id":"25dc9fc7"},"outputs":[],"source":["combined_processed_data = combined_processed_data.append(processed_data_2, ignore_index = True)"]},{"cell_type":"code","execution_count":null,"id":"08c81fc9","metadata":{"id":"08c81fc9"},"outputs":[],"source":["combined_processed_data = combined_processed_data.append(processed_data_3, ignore_index = True)"]},{"cell_type":"code","execution_count":null,"id":"99800360","metadata":{"scrolled":true,"id":"99800360","outputId":"c8692846-2a3f-4ee0-c72b-84a549717fa1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Processed Tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>nice onlin class save money ver trsr nct boyz ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>onlin class pend activ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>school nasad onlin class hahahaha</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>guy hard familiar onlin class haha</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>onlin class fuck sick</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17242</th>\n","      <td>2314</td>\n","      <td>onlin class lazi studi hard</td>\n","    </tr>\n","    <tr>\n","      <th>17243</th>\n","      <td>2315</td>\n","      <td>onlin class guy</td>\n","    </tr>\n","    <tr>\n","      <th>17244</th>\n","      <td>2316</td>\n","      <td>forgot onlin class</td>\n","    </tr>\n","    <tr>\n","      <th>17245</th>\n","      <td>2317</td>\n","      <td>smell onlin class season hope</td>\n","    </tr>\n","    <tr>\n","      <th>17246</th>\n","      <td>2318</td>\n","      <td>hey onlin class readi</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17247 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["       index                                   Processed Tweets\n","0          0  nice onlin class save money ver trsr nct boyz ...\n","1          1                             onlin class pend activ\n","2          2                  school nasad onlin class hahahaha\n","3          3                 guy hard familiar onlin class haha\n","4          4                              onlin class fuck sick\n","...      ...                                                ...\n","17242   2314                        onlin class lazi studi hard\n","17243   2315                                    onlin class guy\n","17244   2316                                 forgot onlin class\n","17245   2317                      smell onlin class season hope\n","17246   2318                              hey onlin class readi\n","\n","[17247 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(combined_processed_data)"]},{"cell_type":"code","execution_count":null,"id":"248fcf4b","metadata":{"scrolled":true,"id":"248fcf4b","outputId":"f5f0dd74-395e-406f-cb40-6dca3314dbec"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Processed Tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>nice onlin class save money ver trsr nct boyz ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>onlin class pend activ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>school nasad onlin class hahahaha</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>guy hard familiar onlin class haha</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>onlin class fuck sick</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13514</th>\n","      <td>2244</td>\n","      <td>clr playlist onlin class</td>\n","    </tr>\n","    <tr>\n","      <th>13515</th>\n","      <td>2245</td>\n","      <td>onlin class tomorrow bye socm feel send flower...</td>\n","    </tr>\n","    <tr>\n","      <th>13516</th>\n","      <td>2265</td>\n","      <td>tbh prefer onlin class situat safe jusko schoo...</td>\n","    </tr>\n","    <tr>\n","      <th>13517</th>\n","      <td>2266</td>\n","      <td>putek troubl studi return onlin class rant cou...</td>\n","    </tr>\n","    <tr>\n","      <th>13518</th>\n","      <td>2304</td>\n","      <td>day set niÃ±a onlin class tvplu antenna broken ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13519 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["       index                                   Processed Tweets\n","0          0  nice onlin class save money ver trsr nct boyz ...\n","1          1                             onlin class pend activ\n","2          2                  school nasad onlin class hahahaha\n","3          3                 guy hard familiar onlin class haha\n","4          4                              onlin class fuck sick\n","...      ...                                                ...\n","13514   2244                           clr playlist onlin class\n","13515   2245  onlin class tomorrow bye socm feel send flower...\n","13516   2265  tbh prefer onlin class situat safe jusko schoo...\n","13517   2266  putek troubl studi return onlin class rant cou...\n","13518   2304  day set niÃ±a onlin class tvplu antenna broken ...\n","\n","[13519 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["clean_data = remove_dup_empty_rows(combined_processed_data)\n","display(clean_data)"]},{"cell_type":"markdown","id":"c6060603","metadata":{"id":"c6060603"},"source":["### Check for Duplicate and Empty Rows"]},{"cell_type":"code","execution_count":null,"id":"3f7697ee","metadata":{"id":"3f7697ee","outputId":"c9849462-4050-42d2-9511-838f1ca8adc0"},"outputs":[{"data":{"text/plain":["index               0\n","Processed Tweets    0\n","dtype: int64"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["clean_data.isnull().sum()"]},{"cell_type":"code","execution_count":null,"id":"beb46d8c","metadata":{"id":"beb46d8c"},"outputs":[],"source":["def dup_rows_index(df):\n","    dup = df[df.duplicated()]\n","    print('Duplicated index loc:',dup[dup == True ].index.tolist())\n","    return dup"]},{"cell_type":"code","execution_count":null,"id":"0b3d2dc0","metadata":{"id":"0b3d2dc0","outputId":"830d2a09-7c45-48c3-ac23-8e79af450f6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Duplicated index loc: []\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Processed Tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [index, Processed Tweets]\n","Index: []"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["dup_rows_index(clean_data)"]},{"cell_type":"markdown","id":"c1c875f7","metadata":{"id":"c1c875f7"},"source":["### Save combined cleaned processed dataset to csv file"]},{"cell_type":"code","execution_count":null,"id":"d4aa32e0","metadata":{"id":"d4aa32e0"},"outputs":[],"source":["clean_data.to_csv('combined_processed-tweets(translated).csv')"]},{"cell_type":"code","execution_count":null,"id":"0cc5ade1","metadata":{"id":"0cc5ade1"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}